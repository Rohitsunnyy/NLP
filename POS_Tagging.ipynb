{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon | PROPN | proper noun\n",
      "flew | VERB | verb\n",
      "to | ADP | adposition\n",
      "mars | NOUN | noun\n",
      "yesterday | NOUN | noun\n",
      ". | PUNCT | punctuation\n",
      "I | PRON | pronoun\n",
      "'m | AUX | auxiliary\n",
      "going | VERB | verb\n",
      "to | PART | particle\n",
      "be | AUX | auxiliary\n",
      "the | DET | determiner\n",
      "new | ADJ | adjective\n",
      "CEO | NOUN | noun\n",
      "of | ADP | adposition\n",
      "SpaceX | PROPN | proper noun\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Elon flew to mars yesterday. I'm going to be the new CEO of SpaceX\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.pos_, \"|\", spacy.explain(token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I | PRON | pronoun | PRP pronoun, personal\n",
      "am | AUX | auxiliary | VBP verb, non-3rd person singular present\n",
      "going | VERB | verb | VBG verb, gerund or present participle\n",
      "to | PART | particle | TO infinitival \"to\"\n",
      "chnage | VERB | verb | VB verb, base form\n",
      "the | DET | determiner | DT determiner\n",
      "name | NOUN | noun | NN noun, singular or mass\n",
      "of | ADP | adposition | IN conjunction, subordinating or preposition\n",
      "X | NOUN | noun | NN noun, singular or mass\n",
      "to | ADP | adposition | IN conjunction, subordinating or preposition\n",
      "something | PRON | pronoun | NN noun, singular or mass\n",
      "new | ADJ | adjective | JJ adjective (English), other noun-modifier (Chinese)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I am going to chnage the name of X to something new\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.pos_, \"|\", spacy.explain(token.pos_), \"|\", token.tag_, spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "earning_text = \"With past Llama models, Meta developed them for ourselves and then released them, but didn’t focus much on building a broader ecosystem. We’re taking a different approach with this release. We’re building teams internally to enable as many developers and partners as possible to use Llama, and we’re actively building partnerships so that more companies in the ecosystem can offer unique functionality to their customers as well. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With | ADP | adposition\n",
      "past | ADJ | adjective\n",
      "Llama | PROPN | proper noun\n",
      "models | NOUN | noun\n",
      ", | PUNCT | punctuation\n",
      "Meta | PROPN | proper noun\n",
      "developed | VERB | verb\n",
      "them | PRON | pronoun\n",
      "for | ADP | adposition\n",
      "ourselves | PRON | pronoun\n",
      "and | CCONJ | coordinating conjunction\n",
      "then | ADV | adverb\n",
      "released | VERB | verb\n",
      "them | PRON | pronoun\n",
      ", | PUNCT | punctuation\n",
      "but | CCONJ | coordinating conjunction\n",
      "did | AUX | auxiliary\n",
      "n’t | PART | particle\n",
      "focus | VERB | verb\n",
      "much | ADV | adverb\n",
      "on | ADP | adposition\n",
      "building | VERB | verb\n",
      "a | DET | determiner\n",
      "broader | ADJ | adjective\n",
      "ecosystem | NOUN | noun\n",
      ". | PUNCT | punctuation\n",
      "We | PRON | pronoun\n",
      "’re | AUX | auxiliary\n",
      "taking | VERB | verb\n",
      "a | DET | determiner\n",
      "different | ADJ | adjective\n",
      "approach | NOUN | noun\n",
      "with | ADP | adposition\n",
      "this | DET | determiner\n",
      "release | NOUN | noun\n",
      ". | PUNCT | punctuation\n",
      "We | PRON | pronoun\n",
      "’re | AUX | auxiliary\n",
      "building | VERB | verb\n",
      "teams | NOUN | noun\n",
      "internally | ADV | adverb\n",
      "to | PART | particle\n",
      "enable | VERB | verb\n",
      "as | ADV | adverb\n",
      "many | ADJ | adjective\n",
      "developers | NOUN | noun\n",
      "and | CCONJ | coordinating conjunction\n",
      "partners | NOUN | noun\n",
      "as | ADP | adposition\n",
      "possible | ADJ | adjective\n",
      "to | PART | particle\n",
      "use | VERB | verb\n",
      "Llama | PROPN | proper noun\n",
      ", | PUNCT | punctuation\n",
      "and | CCONJ | coordinating conjunction\n",
      "we | PRON | pronoun\n",
      "’re | AUX | auxiliary\n",
      "actively | ADV | adverb\n",
      "building | VERB | verb\n",
      "partnerships | NOUN | noun\n",
      "so | SCONJ | subordinating conjunction\n",
      "that | SCONJ | subordinating conjunction\n",
      "more | ADJ | adjective\n",
      "companies | NOUN | noun\n",
      "in | ADP | adposition\n",
      "the | DET | determiner\n",
      "ecosystem | NOUN | noun\n",
      "can | AUX | auxiliary\n",
      "offer | VERB | verb\n",
      "unique | ADJ | adjective\n",
      "functionality | NOUN | noun\n",
      "to | ADP | adposition\n",
      "their | PRON | pronoun\n",
      "customers | NOUN | noun\n",
      "as | ADV | adverb\n",
      "well | ADV | adverb\n",
      ". | PUNCT | punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(earning_text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\"|\", token.pos_, \"|\", spacy.explain(token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(earning_text)\n",
    "\n",
    "filtered_token = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ not in [\"SPACE\", \"X\", \"PUNCT\"]:\n",
    "        filtered_token.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[With,\n",
       " past,\n",
       " Llama,\n",
       " models,\n",
       " Meta,\n",
       " developed,\n",
       " them,\n",
       " for,\n",
       " ourselves,\n",
       " and,\n",
       " then,\n",
       " released,\n",
       " them,\n",
       " but,\n",
       " did,\n",
       " n’t,\n",
       " focus,\n",
       " much,\n",
       " on,\n",
       " building]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_token[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{85: 7,\n",
       " 84: 7,\n",
       " 96: 3,\n",
       " 92: 12,\n",
       " 97: 6,\n",
       " 100: 10,\n",
       " 95: 7,\n",
       " 89: 4,\n",
       " 86: 7,\n",
       " 87: 5,\n",
       " 94: 3,\n",
       " 90: 4,\n",
       " 98: 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[96].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADP | 7\n",
      "ADJ | 7\n",
      "PROPN | 3\n",
      "NOUN | 12\n",
      "PUNCT | 6\n",
      "VERB | 10\n",
      "PRON | 7\n",
      "CCONJ | 4\n",
      "ADV | 7\n",
      "AUX | 5\n",
      "PART | 3\n",
      "DET | 4\n",
      "SCONJ | 2\n"
     ]
    }
   ],
   "source": [
    "for k,v in count.items():\n",
    "    print(doc.vocab[k].text, \"|\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
